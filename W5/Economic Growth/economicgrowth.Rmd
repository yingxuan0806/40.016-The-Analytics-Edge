---
title: "Economic growth Notebook"
output:
  pdf_document: default
  html_notebook: default
  html_document:
    df_print: paged
---

We will use a dataset that was used in the paper: I just ran two million regressions by Sala-I-Martin and Model uncertainty in cross country growth regression by Fernandez et. al. The dataset has 41 possible explanatory variables with 72 countries. The data consists of 43 columns with the Country, y (economic growth in per capita GDP) and 41 possible predictor variables.
```{r results='hide'}
rm(list=ls()) # remove all objects

eg <- read.csv("economicgrowth.csv")
# str(eg)
eg1 <- subset(eg, select = -c(Country))
str(eg1)
```

We now conduct model selection by exhaustive search. Note that we have 2^41 which is approximately 2 trillion possible regressions to run. The leaps package has some smart ways to search over this space by avoiding visiting parts of the space where the optimum cannot exist. It employs a branch and bound algorithm to search more efficiently. This would take a few minutes to run on a laptop. The model shows the bias-variance trade-off. We can also plot the variables identified using the plot command.

```{r fig.height=7,fig.width=7}
library(leaps)
model1 <- regsubsets(y ~ .,data = eg1, nvmax = 41)

plot(summary(model1)$rsq)
plot(summary(model1)$adjr2)
which.max(summary(model1)$adjr2)
plot(model1, scale = c("r2"))
plot(model1, scale = c("adjr2"))
```
We next use the forward stepwise selection method which runs much faster as should be expected. Note that the results are not identical to what we obtained with the exhaustive selection approach. 
```{r fig.height=7,fig.width=7}
model2 <- regsubsets(y ~ ., data = eg1, nvmax = 41, method = "forward")

plot(summary(model2)$rsq)
plot(summary(model2)$adjr2)
plot(model2, scale = c("r2"))
plot(model2, scale = c("adjr2"))
```

Which variables are selected:

```{r results='hide'}
summary(model1)$which[27,]
summary(model2)$which[27,]
```

The results indicate that with model 1, we have   
  1) EquipInv,   
  2) Confucian, EquipInv,   
  3) Buddha, Confucian, EquipInv,   
  4) YrsOpen, Confucian, Protestants, EquipInv   
  
  while for model 2, we have  
  1) EquipInv,   
  2) Confucian, EquipInv,   
  3) Buddha, Confucian, EquipInv,   
  4) Buddha, Protestants, EquipInv, Confucian   
         and so on. The results are different from the two models.

-------------------------------------------------------

LASSO model: The results indicate that for variables such as EquipInv, YrsOpen and Confucian for many values of lambda, these occur while some other variables such as Abslat do not show up as often. Such results help illustrate the reliability of possible predictors for economic growth and can also cast doubts on the robustness of the results for certain variables which might be proposed as being correlated with growth.
```{r}
library(glmnet)
x <- as.matrix(eg1[,c(2:42)])
grid <- 10^seq(10, -2, length=100)
model3 <- glmnet(x, eg1$y, lambda = grid)
model3
# for a large portion, we are not explaining any part for the data for diff lambda values
# at the end, only explained 10% of the null deviance with only 2 variables at the end
# hence this does not seem to be a good grid to look for


# let the R system choose the grid here instead of specifying it
# model3 issues may be perhaps actual lambda values were too small and we were looking at much larger lambda values
model4 <- glmnet(x, eg1$y)
model4
model4$df
model4$beta["EquipInv",]
model4$beta["YrsOpen",]
model4$beta["Confucian",]
model4$beta["Abslat",]

plot(model4, xvar = "lambda")
#model4$beta

# find the set beta coefficient for all lambdas
# whenever a beta is non zero, it gives |
model4$beta !=0
```


